# ===========================================
# MARP Guide RAG Chatbot - Environment Configuration
# ===========================================
# Copy this file to .env and fill in your values

# ===========================================
# RabbitMQ Configuration
# ===========================================
# NOTE: For production, change default guest/guest credentials!
# See: https://www.rabbitmq.com/access-control.html

# RabbitMQ user credentials
RABBITMQ_USER=guest
RABBITMQ_PASSWORD=guest

RABBITMQ_HOST=rabbitmq
RABBITMQ_URL=amqp://guest:guest@rabbitmq:5672/

# ===========================================
# Qdrant Vector Database Configuration
# ===========================================
# NOTE: For production, enable authentication!
# See: https://qdrant.tech/documentation/guides/security/
QDRANT_HOST=qdrant
QDRANT_PORT=6333
QDRANT_COLLECTION=chunks
QDRANT_VECTOR_SIZE=384

# ===========================================
# Embedding Model Configuration
# ===========================================
# Model used for creating embeddings (indexing & retrieval)
# Options: all-MiniLM-L6-v2 (384 dims), all-mpnet-base-v2 (768 dims), etc.
EMBEDDING_MODEL=all-MiniLM-L6-v2

# ===========================================
# Semantic Chunking Configuration
# ===========================================
# Maximum tokens per chunk (affects chunk size and retrieval granularity)
# Default: 400 tokens (~300 words)
# Range: 200-1000 tokens recommended
# - Smaller chunks (200-300): More precise retrieval, more chunks to store
# - Larger chunks (500-1000): More context, fewer chunks, may lose precision
CHUNK_MAX_TOKENS=400

# Tiktoken encoding for token counting
# Default: cl100k_base (used by GPT-4)
# Options: cl100k_base, p50k_base, r50k_base
TIKTOKEN_ENCODING=cl100k_base

# ===========================================
# LLM Configuration (Chat Service)
# ===========================================
# OpenRouter API key for LLM access
OPENROUTER_API_KEY=

# OpenRouter API URL
OPENROUTER_API_URL=https://openrouter.ai/api/v1/chat/completions

# Primary LLM model (legacy, use LLM_MODELS for multiple)
LLM_MODEL=google/gemma-2-9b-it:free

# Multiple LLM models for parallel generation (comma-separated)
# Free models available on OpenRouter:
# - google/gemma-2-9b-it:free
# - meta-llama/llama-3.2-3b-instruct:free
# - microsoft/phi-3-mini-128k-instruct:free
# - mistralai/mistral-7b-instruct:free
# - openai/gpt-oss-20b:free
LLM_MODELS=google/gemma-3-27b-it:free,meta-llama/llama-3.2-3b-instruct:free,mistralai/devstral-2512:free

# LLM generation parameters
LLM_MAX_TOKENS=2000
LLM_TEMPERATURE=0.7
LLM_TIMEOUT=60

# ===========================================
# Vector Search Configuration
# ===========================================
# Number of results to return from vector search
RETRIEVAL_TOP_K=5

# Minimum relevance score threshold (0.0-1.0)
RETRIEVAL_MIN_SCORE=0.0

# ===========================================
# Data Storage
# ===========================================
# Directory for document storage
DATA_DIR=/data

# ===========================================
# Event System Configuration
# ===========================================
EVENT_VERSION=1.0

# ===========================================
# Service Ports (for docker-compose)
# ===========================================
# Ingestion service external port
INGESTION_PORT=8001

# Extraction service external port
EXTRACTION_PORT=8002

# Indexing service external port
INDEXING_PORT=8003

# Retrieval service external port
RETRIEVAL_PORT=8004

# Chat service external port
CHAT_PORT=8005

# RabbitMQ AMQP port
RABBITMQ_AMQP_PORT=5672

# RabbitMQ Management UI port
RABBITMQ_MANAGEMENT_PORT=15672

# Qdrant HTTP API port
QDRANT_HTTP_PORT=6333

# ===========================================
# Logging Configuration
# ===========================================
LOG_LEVEL=INFO

# ===========================================
# RabbitMQ Retry Configuration
# ===========================================
# Maximum number of connection retry attempts
RABBITMQ_MAX_RETRIES=5

# Initial retry delay in seconds
RABBITMQ_INITIAL_RETRY_DELAY=1

# Maximum retry delay in seconds
RABBITMQ_MAX_RETRY_DELAY=30

# Connection timeout in seconds
RABBITMQ_CONNECTION_TIMEOUT=30

# ===========================================
# HTTP Request Timeouts (seconds)
# ===========================================
# Document discovery timeout
DISCOVERY_TIMEOUT=10

# Document download timeout
DOWNLOAD_TIMEOUT=60

# API request timeout
API_TIMEOUT=30
